<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage"><head><!-- Mirrored from www.icme2014.org/call-for-papers by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:38 GMT --><!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
        <script type="text/javascript" src="jquery-1.7.2.min.js"></script>
    <script type="text/javascript">
	$(function () {
		var iframeOffset = $("#mainframe", window.parent.document).offset();
        $("a").each(function () {
            var link = $(this);
            var href = link.attr("href");
            if (href && href[0] == "#") {
                var name = href.substring(1);
                $(this).click(function () {
                    var nameElement = $("[name='" + name + "']");
                    var idElement = $("#" + name);
                    var element = null;
                    if (nameElement.length > 0) {
                        element = nameElement;
                    } else if (idElement.length > 0) {
                        element = idElement;
                    }

                    if (element) {
                        var offset = element.offset();
                        window.parent.scrollTo(offset.left, offset.top + iframeOffset.top);
                    }

                    return false;
                });
            }
        });
	});
	</script>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />

<link rel="canonical" href="call-for-papers.html" />
<meta name="title" content="Call for Papers - ICME 2016" />
<meta itemprop="name" content="Call for Papers - ICME 2016" />
<meta property="og:title" content="Call for Papers - ICME 2016" />
<meta name="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta itemprop="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta id="meta-tag-description" property="og:description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<link rel="stylesheet" type="text/css" href="../www.gstatic.com/sites/p/158cce/system/app/themes/solitudenavy/standard-css-solitudenavy-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/overlay6de5.css?cb=solitudenavy1000px200goog-ws-leftcontent30middlecenter" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/camelot/allthemes-view.css" /><!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->

<meta itemprop="image" content="/_/rsrc/1340688868168/config/customLogo.gif?revision=2" />
<meta property="og:image" content="/_/rsrc/1340688868168/config/customLogo.gif?revision=2" />
    <style type="text/css">

        .auto-style1 {
            text-align: justify;
        }
        .auto-style2 {
            font-size: medium;
        }
        .newStyle1 {
            font-family: Tahoma;
        }
        </style>
    <link rel="stylesheet" type="text/css" href="css/body.css" /></head>
<body xmlns="http://www.google.com/ns/jotspot" id="body">
<div id="sites-canvas">
<h3 id="sites-page-title-header" class="newStyle1" align="center">
    Plenary Talks</h3>
<div id="sites-canvas-main-content">    
<table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0">
    <tbody><tr><td><div class="auto-style1" dir="ltr"><div></div><br />
        <span style="line-height: 1.5; font-size: 1em;">
            <table style="">
                <tbody><tr>                    
                    <td><a name="feifei" id="feifei"></a>                        
                        <img src="files/plenary/feifei_li.jpg" style="height: 176px; width: 176px;" />                            
                    </td>          
                    
                    <td>
                        <span style="line-height: 0.8;" class="auto-style2">
        <span style="line-height: 1.5; font-size: 1em;">
                        <span style="line-height: 1.5;" class="auto-style2"><a href="http://vision.stanford.edu/feifeili/" target="_blank"><strong>Fei-Fei Li</strong></a>, <em>Associate Professor, Stanford University</em></span></span>
                         <br /><br />
                            <strong>Talk title: A Quest for Visual Intelligence in Computers</strong>
                        </span><span style="line-height: 1.5; font-size: 1em;">&nbsp;<p><span style="line-height: 1.5;" class="auto-style2"><strong>Abstract:</strong></span><br />
                                It takes nature and evolution more than five hundred million years to develop a powerful visual system in humans. The journey for AI and computer vision is about fifty years. In this talk, I will briefly discuss the key ideas and the cutting edge advances in the quest for visual intelligences in computers. I will particularly focus on the latest work developed in my lab for both image and video understanding, powered by big data and the deep learning (a.k.a. neural network) architecture.
                            </p></span>
                        <p><span style="line-height: 1.5;" class="auto-style2"><strong>Bio:</strong></span> <br />
                            Dr. Fei-Fei Li is an Associate Professor in the Computer Science Department at Stanford, and the Director of the Stanford Artificial Intelligence Lab and the Stanford Vision Lab. She is also the Director of the recently established Stanford Toyota Center for Human-Centric AI Research. Dr. Fei-Fei Liâ€™s main research areas are in machine learning, computer vision and cognitive and computational neuroscience. She has published more than 100 scientific articles in top-tier journals and conferences, including Nature, PNAS, Journal of Neuroscience, CVPR, ICCV, NIPS, ECCV, IJCV, IEEE-PAMI, etc. Dr. Fei-Fei Li obtained her B.A. degree in physics from Princeton in 1999 with High Honors, and her PhD degree in electrical engineering from California Institute of Technology (Caltech) in 2005.  She joined Stanford in 2009 as an assistant professor, and was promoted to associate professor with tenure in 2012. Prior to that, she was on faculty at Princeton University (2007-2009) and University of Illinois Urbana-Champaign (2005-2006). Dr. Fei-Fei Li is a speaker at the TED2015 main conference, a recipient of the 2014 IBM Faculty Fellow Award, 2011 Alfred Sloan Faculty Award, 2012 Yahoo Labs FREP award, 2009 NSF CAREER award, the 2006 Microsoft Research New Faculty Fellowship and a number of Google Research awards. Work from Dr. Li's lab have been featured in a variety of popular press magazines and newspapers including New York Times, Science, Wired Magazine, and New Scientists.
                        </p>
                        <p>&nbsp;</p></span>
                    </td>
                </tr>                
                <tr>
                    <td>
                        <a name="billinghurst" id="billinghurst"></a>
                        <img src="files/plenary/mark_billinghurst.jpg" style="height: 176px; width: 176px;" /></td>          
                    
                    <td>
                        <span style="line-height: 1.5;" class="auto-style2"><a href="http://www.unisanet.unisa.edu.au/staff/homepage.asp?Name=Mark.Billinghurst" target="_blank"><strong>Mark Billinghurst</strong></a></span><span style="line-height: 1.5; font-size: 1em;"><span style="line-height: 1.5;" class="auto-style2">, <em>Professor, University of South Australia</em><span style="line-height: 0.8;" class="auto-style2"><p><strong>Talk title: Empathic Computing: Design for Understanding</strong></p></span></span>
                        <p><strong><span style="line-height: 2;" class="auto-style2">Abstract:</span></strong><br />In an era where people share more about themselves than ever before, can
technology be used to create deeper empathy and understanding? This
talk describes Empathic Computing, systems that help people better
understand each other, and how to design for understanding. There have
been several decades of research on Affective Computing systems that
recognise a users emotion, but until recently there has been little
research on how to use technology to share emotions between people.
Technology such as wearable computing, smart sensors, and Augmented and
Virtual Reality, can be combined together to enable people to capture
their surroundings and feelings and share them with others. In order to
do this there are interesting problems to be solved in recognising
emotion, repenting emotion, and measuring the impact of emotion, among
other topics. Examples of how to do this will be shared from leading
research groups, including the Empathic Computing Laboratory at the
University of South Australia, and directions described for future
work. The 1980's were about Multi-media, the 2000's Social Media and
2020's could be the decade of Empathic Media.</p>
                        <p><span style="line-height: 1.5;" class="auto-style2"><strong>Bio:</strong></span> <br />
Mark Billinghurst is Professor of Human Computer Interaction at the
University of South Australia in Adelaide, Australia. He earned a PhD
in 2002 from the University of Washington and researches innovative
computer interfaces that explore how virtual and real worlds can be
merged, publishing over 300 papers in topics such as wearable
computing, Augmented Reality and mobile interfaces. Prior to joining
the University of South Australia he was Director of the HIT Lab NZ at
the University of Canterbury and he has previously worked at British
Telecom, Nokia, Google and the MIT Media Laboratory. His MagicBook
project, was winner of the 2001 Discover award for best entertainment
application, and he received the 2013 IEEE VR Technical Achievement
Award for contributions to research and commercialization in Augmented
Reality. In 2013 he was selected as a Fellow of the Royal Society of
New Zealand.</p>
                        <p>&nbsp;</p></span></td>
                </tr>
                <tr>
                    <td>
                        <a name="dariu" id="dariu"></a>
                        <img src="files/plenary/dariu.jpg" style="height: 176px; width: 176px;" /></td>          
                    
                <td>
                    <span style="line-height: 1.5;" class="auto-style2"><a href="http://www.gavrila.net" target="_blank"><strong>Dariu M. Gavrila</strong></a></span><span style="line-height: 1.5; font-size: 1em;"><span style="line-height: 1.5;" class="auto-style2">, <em>Distinguished Scientist, Daimler R&amp;D in Ulm</em></span>  
                        <br /></span>

                        <span style="line-height: 0.8;" class="auto-style2"><p><strong>Talk Title: The Intelligent Vehicles (R)evolution</strong></p></span>
                        <p><strong><span style="line-height: 2;" class="auto-style2">Abstract:</span></strong><br />
The automotive field is in the midst of a transformation. Cheap sensors and powerful
hardware, coupled with machine learning algorithms and big data rapidly advance
the capabilities of modern vehicles. In the traditional vehicle sector, where
the driver is under control, the automation level is gradually increased;
witness the ever more sophisticated autopilots for the highway introduced in
premium cars nowadays (e.g. Mercedes-Benz E-Class 2016 Drive Pilot). At the
same time, a new vehicle sector is emerging:<span style="">&nbsp;
</span>that of self-driving vehicles, where the human driver is no longer
necessary and where control is exerted remotely by an operator, as part of a
mobility service. <span style="">&nbsp;</span><o:p></o:p></span></p>

<p class="MsoNormal"><span style="" lang="EN-US">What can be
automated in a vehicle?<span style="">&nbsp; </span>Why does vehicle
automation make sense? How does the technology work? What are the remaining
hurdles? When will automated vehicles come about? This talk will provide some
answers.<o:p></o:p></span></p>
<span style="line-height: 1.5; font-size: 1em;">
                        </span></span></p><span style="line-height: 1.5; font-size: 1em;"><p><span style="line-height: 1.5;" class="auto-style2"><strong>Bio:</strong></span> <br />
Dariu M. Gavrila received the MSc degree in computer science from the
Vrije University in Amsterdam in 1990. He received the PhD degree in
computer science from the University of Maryland at College Park, USA,
in 1996. Since 1997, he has been with Daimler R&amp;D in Ulm, Germany,
where he is currently a Distinguished Scientist. In 2003, he was also
appointed professor in the Faculty of Science at the University of
Amsterdam, chairing the area of Intelligent Perception Systems (part
time). Over the past 15 years, Prof. D. M. Gavrila has worked on
perception systems for detecting humans and their activity, with
application to intelligent vehicles, smart surveillance and social
robotics. He led the multi-year pedestrian detection research effort at
Daimler which was incorporated in the Mercedes-Benz S-, E-, and C-Class
models (2013-2014). Prof. D. M. Gavrila published 50+ papers in
top-tier conferences and journals, and is frequently cited in his
domain (Google Scholar: about 10.000 times). He served as Area Chair at
previous IV, ICCV, AVSS, and DAGM conferences; he is currently Program
Co-Chair for the upcoming IEEE Intelligent Vehicles (IV) 2016
conference in GÃ¶theborg, Sweden. He delivered keynotes at previous IV,
ICVS, AVSS, CAIP and Ã–AGM conferences. For the societal impact of his
research, Prof. D. M. Gavrila received the I/O 2007 Award from the
Netherlands Organisation for Scientific Research (NWO) and the IEEE
Intelligent Transportation Systems Application Award 2014 (the latter
as part of a Daimler team). He has had regular appearances in the
German/Dutch broadcast and print media. </p></span></td>
                </tr>

            </tbody></table>            
    </span></div>

 

<!-- Mirrored from www.icme2014.org/call-for-papers by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:40 GMT -->
</td></tr></tbody></table></div></div></body></html>