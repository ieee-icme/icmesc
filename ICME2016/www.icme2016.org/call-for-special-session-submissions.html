<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
    <head><!-- Mirrored from www.icme2014.org/call-for-special-session-proposals by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:41 GMT --><!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<meta http-equiv="X-UA-Compatible" content="chrome=1" />

<link rel="canonical" href="call-for-special-session-proposals.html" />
<meta name="title" content="Call for Special Session Proposals - ICME 2016" />
<meta itemprop="name" content="Call for Special Session Proposals - ICME 2016" />
<meta property="og:title" content="Call for Special Session Proposals - ICME 2016" />
<meta name="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta itemprop="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta id="meta-tag-description" property="og:description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />

<style type="text/css">
    .auto-style1 {
        font-size: large;
    }
    .auto-style2 {
        font-size: medium;
    }
</style>
<link rel="stylesheet" type="text/css" href="../www.gstatic.com/sites/p/158cce/system/app/themes/solitudenavy/standard-css-solitudenavy-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/overlay6de5.css?cb=solitudenavy1000px200goog-ws-leftcontent30middlecenter" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/camelot/allthemes-view.css" /><!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->


<title>Call for Special Session Proposals - ICME 2016</title>
        <link rel="stylesheet" type="text/css" href="css/body.css" />   
    </head>




<body xmlns="http://www.google.com/ns/jotspot" id="body" class="newStyle1">

    <div id="sites-canvas">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
</div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="center">
<span id="sites-page-title" dir="ltr">Call for Special Session Submissions</span>
</h3>
<div id="sites-canvas-main-content"><div dir="ltr">
<div></div>
<br />
    <div style="text-align: justify;">
    <span style="line-height: 1.5; font-size: 1em;">    
        <!--Download PDF version of this call for special session proposals.
        <br /><br />-->
Special Sessions supplement the regular program of ICME 2016 and are
intended to provide a sample of the state-of-the-art and highlight
important research directions in a field of special interest to ICME
participants. <br />
        <br />
        The original Call for Special Session Proposals can be found <a href="call-for-special-session-proposals.html">here</a>.
        <br />
        <br />
This year, we have selected four proposals for our Special Session
Program as listed below. Note submission to any of the special sessions
is open to everyone. Papers submitted to a special session will undergo
the same rigorous review process as regular papers to ensure that the
contributions are of high quality. If your paper is accepted, we
reserve the right to place the paper in either the special session or
the regular session. <br /><br />
For additional information regarding the Special Sessions, please
contact one of the Special Session co-chairs, Dr. Aljosa Smolic <a href="mailto:%28aljoscha.smolic@gmail.com">(aljoscha.smolic@gmail.com</a>) or Dr. Luigi Atzori <a href="mailto:%28l.atzori@ieee.org">(l.atzori@ieee.org</a>).
        <br /><br />
        </span>
         <strong>
    <span style="line-height: 1.5;" class="auto-style1">    
        Important Dates
        <br />
        </span>
    <span style="line-height: 1.5; font-size: 1em;">    
        <br />
        </span>
        </strong>
    <span style="line-height: 1.5; font-size: 1em;">    
        Special Session Abstract Submission: November 30, 2015
        <br />
        Special Session Paper Submission: <span style="text-decoration: line-through;">December 4, 2015
       </span> &nbsp; &nbsp;</span><span style="line-height: 1.5; font-size: 1em; font-weight: bold; color: red;">December 11, 2015
        </span><br /><span style="line-height: 1.5; font-size: 1em;">
        Notification of Paper Acceptance: March 11, 2016        
        <br /><br />
        <strong><span class="auto-style1">Accepted Special Sessions</span></strong>
        <br /><br />
        </span>
        <span>
    <span style="line-height: 1.5;" class="auto-style2">
            <strong>Perceptual Visual Processing for Multimedia Communication Systems<br />
            </strong>
        </span>
    <span style="line-height: 1.5; font-size: 1em;">
                <div>
                    <em>Yuming Fang, Jiangxi University of Finance and Economics, Nanchang, China<br />
                Hantao Liu, Cardiff University, UK <br />
                Zhenzhong Chen, Wuhan University, China <br />
                Weisi Lin, Nanyang Technological University, Singapore
               </em>
               </div>
                <br />
                <div>
                    <div>Delivering
an optimized quality of experience (QoE) to the end user is a
fundamental challenge for various multimedia communication systems. As
we know, most of the visual information is finally consumed by the
Human Visual System (HVS). Thus, visual processing always involves
various factors related to human perception, human emotion and
behaviour, human experiences as well as the characteristics of visual
processing systems/techniques. To provide a promising QoE model for
various multimedia processing applications, we have to investigate
these perceptual and system factors. </div>
                    <br /><div>This
special session seeks submissions about the latest technology
developments in the areas of perceptual visual processing, as well as
the potential applications and systems in the related area. We will
mainly focus on the new developments and applications of visual
attention and visual quality assessment. Specifically, for the visual
quality assessment, besides the general-purpose visual quality
assessment (VQA), we will also focus on the emerging quality assessment
for various specific applications, such as VQA for screen content
images (SCI), graphics, high dynamic ranging (HDR) images, high
definition television video (HDTV), 3D images/video, etc.</div>
                </div>
        </span>
        </span>            
    
    <br />
            <span>
    <span style="line-height: 1.5;" class="auto-style2">
            <strong>Free Navigation and Immersive 3D<br />
            </strong>
        </span>
    <span style="line-height: 1.5; font-size: 1em;">
                <div>
                    <em>Masayuki Tanimoto, Nagoya Industrial Science Research Institute, Japan<br />
                Gauthier Lafruit, Université Libre de Bruxelles, Belgium<br />
                Dr. Joël Jung, IRT B-COM, France
               </em>
               </div>
                <br />
                <div>
                    <div>Eager
to provide the user a rich multimedia experience, companies constantly
innovate in novel display modalities, introducing advanced digital
image post-processing into the rendering pipeline. So far, however,
most viewing remains limited to a single or stereoscopic visualization
with little immersive experience, excluding motion parallax and Free
Navigation features as offered in the real world.</div>
                    <br /><div>Today,
computational light field cameras already offer narrow,
user-perspective parallax rendering capabilities. Tomorrow,
Free-viewpoint Television (FTV) will give the user complete freedom in
choosing any viewpoint within a multi-camera-enclosed volume, reaching
the ultimate, immersive experience. </div>
                    <br /><div>A
key challenge resides in developing realistic technology and image
processing methods that support the synthesis of novel views at
rendering time with correct occlusion handling, inpainting and data
recovery mechanisms from sparse camera arrangements. Standardization
activities such as MPEG-FTV and JPEG-PLENO are currently exploring
these challenges. </div>
                    <br /><div>This special
session explores new advances in Free Navigation and Immersive 3D
technologies. Ground-breaking scientific and technological papers are
solicited, bringing new insights in this era. The paper subjects range
from new capture and display technologies to novel mathematical
insights in light field data sampling and representation, mixing
diverse modalities (point clouds, image-based rendering, plenoptic
processing), as well as improvements in compression formats.</div>
                </div>
        </span>
        </span>            

    <br />
            <span>
    <span style="line-height: 1.5;" class="auto-style2">
            <strong>Multimedia Big Data and Cloud Computing <br />
            </strong>
        </span>
    <span style="line-height: 1.5; font-size: 1em;">
                <div>
                    <em>Zheng-Jun Zha, University of Science and Technology of China, China<br />
                Gwendal Simon, Telecom Bretagne, Institute Mine Telecom, France<br />
                Shervin Shirmohammadi, University of Ottawa, Canada<br />
                Xiaokang Yang, Shanghai Jiao Tong University, China
               </em>
               </div>
                <br />
                <div>
                    <div>“Big
Data” has become a ubiquitous term in recent years and multimedia is
becoming the “biggest Big Data.” Multimedia big data comes from sources
as varied as security cameras, medical imaging, and individuals sharing
media on Internet. It is the most important and valuable source for
insights and information. Multimedia big data is spurring on huge
amounts of research and development of related technologies and
applications. </div>
                    <br /><div>To deal with this
tremendous amount of data to process, another term has become
ubiquitous: "cloud computing." This mainstream idiom encompasses a set
of hardware and software technologies, which have all in common that
they deal with multimedia content. Still in their infancy, they also
have to evolve to meet the demand for more computing and, eventually
more QoE for the end-users, with respect to global energy consumption.</div>
                    <br /><div>A
key challenge resides in developing realistic technology and image
processing methods that support the synthesis of novel views at
rendering time with correct occlusion handling, inpainting and data
recovery mechanisms from sparse camera arrangements. Standardization
activities such as MPEG-FTV and JPEG-PLENO are currently exploring
these challenges. </div>
                    <br /><div>This special
session will provide a venue for the participants to discuss key
research issues on multimedia big data and cloud computing. It will
collect and seek the recent important research works in this area,
summarize the available resources, and exploit potential challenges and
possible advanced solutions in terms of theory and practice. </div>
                </div>
        </span>
        </span>

            <br />
            <span>
    <span style="line-height: 1.5;" class="auto-style2">
            <strong>Deep Learning for Multimedia Computing<br />
            </strong>
        </span>
    <span style="line-height: 1.5; font-size: 1em;">
                <div>
                    <em>Benoit Huet, Eurecom, France<br />
                Jiebo Luo, University of Rochester, USA<br />
                Guo-Jun Qi, University of Central Florida, USA
               </em>
               </div>
                <br />
                <div>
                    <div>Conventional
multimedia computing is often built on top of handcrafted features,
which are often much restrictive in capturing complex multimedia
content such as images, audios, text and user-generated data with
domain-specific knowledge. Recent progress on deep learning opens an
exciting new era, placing multimedia computing on a more rigorous
foundation with automatically learned representations to model the
multimodal data and the cross-media interactions. Existing studies have
revealed promising results that have greatly advanced the
state-of-the-art performance in a series of multimedia research areas,
from the multimedia content analysis, to modeling the interactions
between multimodal data, to multimedia content recommendation systems,
to name a few here. </div>
                    <br /><div>This ICME
2016 Special Session aims at providing a forum to present recent
advancements in deep learning research that directly concerns the
multimedia community. Specifically, deep learning has successfully
designed algorithms that can build deep nonlinear representations to
mimic how the brain perceives and understands multimodal information,
ranging from low-level signals like images and audios, to high-level
semantic data like natural language. For multimedia research, it is
especially important to develop deep networks to capture the
dependencies between different genres of data, building joint deep
representation for diverse modalities.</div>
                </div>
        </span>
        </span>            
                </div>

</div>
</div></div> 
<div id="sites-canvas-bottom-panel">
<div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
<div id="sites-attachments-container">
</div>
</div>

<!-- Mirrored from www.icme2014.org/call-for-special-session-proposals by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:41 GMT -->
</body></html>