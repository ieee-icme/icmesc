<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage"><head><!-- Mirrored from www.icme2014.org/call-for-papers by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:38 GMT --><!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<meta http-equiv="X-UA-Compatible" content="chrome=1" />

<link rel="canonical" href="handson.html" />
<meta name="title" content="Hands-On Expo - ICME 2016" />
<meta itemprop="name" content="Hands-On Expo - ICME 2016" />
<meta property="og:title" content="Hands-On Expo - ICME 2016" />
<meta name="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta itemprop="description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<meta id="meta-tag-description" property="og:description" content="The 2016 IEEE International Conference on Multimedia &amp; Expo" />
<link rel="stylesheet" type="text/css" href="../www.gstatic.com/sites/p/158cce/system/app/themes/solitudenavy/standard-css-solitudenavy-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/overlay6de5.css?cb=solitudenavy1000px200goog-ws-leftcontent30middlecenter" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/camelot/allthemes-view.css" /><!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->

    <style type="text/css">
        .auto-style1 {
            text-align: justify;
        }
    a:link
	{color:blue;
	text-decoration:underline;
	text-underline:single;
        }
    </style>
    <link rel="stylesheet" type="text/css" href="css/body.css" /></head>
<body xmlns="http://www.google.com/ns/jotspot" id="body" class="newStyle1">
<div id="sites-canvas">
<div id="goog-ws-editor-toolbar-container"> </div>
<div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
</div>
<h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="center"><big>
<span id="sites-page-title" dir="ltr">Hands-On Expo</span>
</big></h3>
<div id="sites-canvas-main-content">
<table xmlns="http://www.w3.org/1999/xhtml" class="sites-layout-name-one-column sites-layout-hbox" cellspacing="0"><tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr"><div></div>
<div>
    <br />
    </div><span style="line-height: 1.5; font-size: 1em;">The
Hands-On Expo is an exciting new program element being introduced at
ICME 2016. The Hands-On Expo brings companies that have ground breaking
new media-related products together with world class multimedia
researchers and technologists, to give the latter a hands-on experience
of the products and a deeper understanding of the technologies behind
the products and how to use them. We currently have one session
confirmed, others are in the process of being confirmed and will be
posted soon.<br /><br /><big><span style="font-weight: bold; color: rgb(63, 168, 255);">Hands-On Expo No. 1: Microsoft Cognitive Services</span></big><br style="font-weight: bold;" /></span><big><span style="color: rgb(80, 80, 80); font-family: Arial; font-size: 14.6667px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 20px; text-align: justify; text-indent: 0px; text-transform: none; white-space: normal; widows: 1; word-spacing: 0px; display: inline ! important; float: none; background-color: rgb(255, 255, 255);"><span class="Apple-converted-space"></span></span></big><span style="line-height: 1.5; font-size: 1em;"><big><span style="font-weight: bold;">Presenter</span><span style="font-weight: bold;">s: &nbsp; &nbsp;<span style="color: rgb(63, 168, 255);">&nbsp;</span></span><br style="font-weight: bold;" /><span style="font-weight: bold;"></span></big></span><span style="line-height: 1.5; font-size: 1em;"><big><span style="font-weight: bold;"><span style="color: rgb(63, 168, 255);">Cha Zhang</span> (Principal Researcher, Microsoft Research)<br /><span style="color: rgb(63, 168, 255);">Emad Barsoum</span> (Principal Developer, Microsoft Research)<br /><span style="color: rgb(63, 168, 255);">Kenneth Tran</span> (Senior Developer, Microsoft Research)</span><span style="line-height:1.5;font-size:1em"><p style="font-weight: 700">Time: 14:40-16:40, 
        Wednesday, July 13, 2016
                                                 <br />Room: Blakely
                                                </p>
                                    </span></big><span style="font-weight: bold;"><big>Description</big></span></span><br /><br /><b class="auto-style1"><span style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US">Microsoft Cognitive Services</span></b><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US"> is a set of APIs and SDKs for computer
vision, speech, language processing, and search based on research in machine
intelligence from Microsoft. These REST APIs make it easy to build intelligent
experiences with images, video, text and speech understanding on any platform.
This session will include technical talks by the researchers behind Emotion and
Image Captioning API, followed an hour of hands on workshop where you’ll learn
how to build an experience using our Vision API and Language Understanding Intelligent
Service. <br /><br /></span><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80); font-weight: bold;" lang="EN-US">Technical Talks:</span><span class="auto-style1" style="font-weight: bold;">

</span>

<br class="auto-style1" /><b class="auto-style1"><span style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US"><br />Image Captioning</span></b><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US">: We present an image caption system, </span><span class="auto-style1" lang="EN-US"><a href="http://captionbot.ai/"><span style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;">http://CaptionBot.ai</span></a></span><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US">, that addresses new challenges of
automatically describing images in the wild. The challenges include high quality
caption quality with respect to human judgments, out-of-domain data handling,
and low latency required in many applications. Built on top of a
state-of-the-art framework, we developed a deep vision model that detects a
broad range of visual concepts, an entity recognition model that identifies
celebrities and landmarks, and a confidence model for the caption output. <o:p></o:p></span><span class="auto-style1">

</span>

<br class="auto-style1" /><b class="auto-style1"><span style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US"><br />Emotion Recognition:</span></b><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US"> Recognizing people's emotions has many
potential applications including advertising, gaming, autism intervention,
personal assistant, etc. In this talk, I'll present our effort in creating the </span><span class="auto-style1" lang="EN-US"><a href="https://www.microsoft.com/cognitive-services/en-us/emotion-api"  target="_blank"><span style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;;">Emotion
API</span></a></span><span class="auto-style1" style="font-family: &quot;Arial&quot;,&quot;sans-serif&quot;; color: rgb(80, 80, 80);" lang="EN-US"> for images in the
wild. Due to the subjective nature of emotions, we faced challenges in how to
best utilize the unreliable crowd sourcing data to train our emotion model. A
deep learning based method is applied with stochastic training targets, which
achieved state-of-the-art results. <o:p></o:p></span><br class="auto-style1" />
<br /><span style="line-height: 1.5; font-size: 1em;"><br /></span><span style="line-height: 1.5; font-size: 1em;"><big><span style="font-weight: bold; color: rgb(63, 168, 255);">Hands-On Expo No. 2: Intel RealSense</span></big><br style="font-weight: bold;" /></span><big><span style="color: rgb(80, 80, 80); font-family: Arial; font-size: 14.6667px; font-style: normal; font-variant: normal; font-weight: normal; letter-spacing: normal; line-height: 20px; text-align: justify; text-indent: 0px; text-transform: none; white-space: normal; widows: 1; word-spacing: 0px; display: inline ! important; float: none; background-color: rgb(255, 255, 255);"><span class="Apple-converted-space"></span></span></big><span style="line-height: 1.5; font-size: 1em;"><big><span style="font-weight: bold;">Presenter</span><span style="font-weight: bold;">: &nbsp; &nbsp;<span style="color: rgb(63, 168, 255);">&nbsp;Anders Grunnet-Jepsen</span>, Ph.D.</span><br style="font-weight: bold;" /><span style="font-weight: bold;">CTO &amp; Director of Advanced Technology Group, Perceptual Computing, Intel Corporation</span><span style="line-height:1.5;font-size:1em"><p style="font-weight: 700">Time: 13:00-16:00, 
        Thursday, July 14, 2016
                                                 <br />Room: Vashon
                                                </p>
                                    </span></big><span style="font-weight: bold;"><big>Description</big><br /><br /></span>Intel’s
RealSense Technology is making great strides in “sensifying computing”
by providing breakthrough innovation in hardware and software. Intel is
developing a family of RealSense Depth Cameras, processors, image
processors, and application specific integrated circuits that will
allow a computer to sense its surroundings much like humans are able
to, to capture the world in both shape and color.&nbsp; These sensors
are currently in over a million PCs today.&nbsp; This technology is
very exciting in bringing new features to PCs and laptops where you can
now use them to scan people, objects and rooms in 3D in a matter of
minutes, or do instant live green-screen background segmentation or
allow for remote gesture interaction with a computer, to name a
few.&nbsp; However, where we see major growth opportunity for this
technology is in new markets emerging that are growing fast, including
drones, robots, AR/VR, and smart buildings and homes. This talk will
present Intel’s depth sensors and show how they are being applied to
PCs and beyond. The presentation will take about 1.5 hrs and it will be
followed by the handing out of a limited number of RealSense Camera
modules. We will walk you through the installation (briefly) and will
focus on bringing you quickly up and showing you some samples in the
RealSense SDK.&nbsp; Please bring your own Windows 10 (or Windows 8)
Laptop with a USB3 connector.&nbsp; Other operating systems are also
supported, but will not be demoed.<br /></span><br /></div></td></tr></tbody></table></div></div></body></html>