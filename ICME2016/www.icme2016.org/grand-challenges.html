<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" itemscope="" itemtype="http://schema.org/WebPage">

<!-- Mirrored from www.icme2014.org/call-for-papers by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:38 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=utf-8" /><!-- /Added by HTTrack -->
<head>
<meta http-equiv="X-UA-Compatible" content="chrome=1" />
<script type="text/javascript">/* Copyright 2008 Google. */ (function() { var b=window,e="chrome",g="tick",h="wtsrt_",l="tbsd_",m="tbnd_",n="start",p="_wtsrt",q="_tbnd",r="CSI/index.html";(function(){function k(a){this.t={};this.tick=function(a,d,c){this.t[a]=[void 0!=c?c:(new Date).getTime(),d];if(void 0==c)try{b.console.timeStamp(r+a)}catch(f){}};this[g](n,null,a)}var a;b.performance&&(a=b.performance.timing);var s=a?new k(a.responseStart):new k;b.jstiming={Timer:k,load:s};if(a){var d=a.navigationStart,f=a.responseStart;0<d&&f>=d&&(b.jstiming.srt=f-d)}if(a){var c=b.jstiming.load;0<d&&f>=d&&(c[g](p,void 0,d),c[g](h,p,f),c[g](l,h))}try{a=null,b[e]&&b[e].csi&&(a=Math.floor(b[e].csi().pageT),
c&&0<d&&(c[g](q,void 0,b[e].csi().startE),c[g](m,q,d))),null==a&&b.gtbExternal&&(a=b.gtbExternal.pageT()),null==a&&b.external&&(a=b.external.pageT,c&&0<d&&(c[g](q,void 0,b.external.startE),c[g](m,q,d))),a&&(b.jstiming.pt=a)}catch(t){}})(); })()
</script>
<link rel="shortcut icon" type="image/x-icon" href="http://www.google.com/images/icons/product/sites-16.ico" />
<link rel="apple-touch-icon" href="../www.gstatic.com/sites/p/158cce/system/app/images/apple-touch-icon.png" type="image/png" />
<link rel="canonical" href="call-for-papers.html" />
<meta name="title" content="Call for Papers - ICME 2014" />
<meta itemprop="name" content="Call for Papers - ICME 2014" />
<meta property="og:title" content="Call for Papers - ICME 2014" />
<meta name="description" content="The 2014 IEEE International Conference on Multimedia &amp; Expo" />
<meta itemprop="description" content="The 2014 IEEE International Conference on Multimedia &amp; Expo" />
<meta id="meta-tag-description" property="og:description" content="The 2014 IEEE International Conference on Multimedia &amp; Expo" />
<link rel="stylesheet" type="text/css" href="../www.gstatic.com/sites/p/158cce/system/app/themes/solitudenavy/standard-css-solitudenavy-ltr-ltr.css" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/overlay6de5.css?cb=solitudenavy1000px200goog-ws-leftcontent30middlecenter" />
<link rel="stylesheet" type="text/css" href="_/rsrc/1403685870000/system/app/css/camelot/allthemes-view.css" />
<!--[if IE]>
          <link rel="stylesheet" type="text/css" href="/system/app/css/camelot/allthemes%2die.css" />
        <![endif]-->
<title>Call for Papers - ICME 2014</title>
<meta itemprop="image" content="/_/rsrc/1340688868168/config/customLogo.gif?revision=2" />
<meta property="og:image" content="/_/rsrc/1340688868168/config/customLogo.gif?revision=2" />
<link rel="stylesheet" type="text/css" href="css/body.css" />   
<script type="text/javascript">
                window.jstiming.load.tick('cl');
              </script>
    <style type="text/css">
        .auto-style1 {
            text-align: justify;
        }
        .auto-style2 {
            text-align: justify;
            font-size: 12.0pt;
            font-family: Calibri, sans-serif;
            margin-left: 24.0pt;
            margin-right: 0in;
            margin-top: 0in;
            margin-bottom: .0001pt;
            background: white;
        }
    </style>
</head>


<body xmlns="http://www.google.com/ns/jotspot" id="body" class="newStyle1">
    <div id="sites-canvas">
        <div id="goog-ws-editor-toolbar-container"> </div>
        <div xmlns="http://www.w3.org/1999/xhtml" id="title-crumbs" style="">
        </div>
        <h3 xmlns="http://www.w3.org/1999/xhtml" id="sites-page-title-header" style="" align="center">
            <span id="sites-page-title" dir="ltr">Grand Challenges</span>
        </h3>
<div id="sites-canvas-main-content">
                <table xmlns="http://www.w3.org/1999/xhtml" cellspacing="0" class="sites-layout-name-one-column sites-layout-hbox">
                    <tbody><tr><td class="sites-layout-tile sites-tile-name-content-1"><div dir="ltr" class="auto-style1"><div></div>
                                    <span style="line-height:1.5;font-size:1em">
                                        <div class="auto-style1">
                                            <div class="  textBox" style="">
                                                <h3 id="challenge-description">1. Grand Challenge on Light-Field Image Compression</h3>

                                                <h4 style="text-align: justify;" id="Organizers">Challenge Organizers: Touradj Ebrahimi, Peter Schelkens, Fernando Pereira</h4>




            <span style="line-height:1.5;font-size:1em">
                                                
                                                <p style="font-weight: 700">Time: 10:00-11:40, Tuesday, July 12, 2016
                                                 <br />Room: Grand III
                                                </p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Pseudo-Sequence-Based Light Field Image Compression</span> <span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt"><o:p></o:p></span></b>
                                                </p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Dong Liu<sup>1</sup>, Lizhi Wang<sup>2</sup>, Li Li<sup>1</sup>, Zhiwei Xiong<sup>3</sup>, Feng Wu<sup>1</sup>, Wenjun Zeng<sup>3<o:p></o:p></sup></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">University of Science &amp; Technology of China<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Xidian University<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">3</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Microsoft Research Asia<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                                                    <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">HEVC-based Light Field Image Coding with Bi-Predicted Self-Similarity Compensation<o:p></o:p></span></b></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Caroline Conti, Paulo Nunes, Luís Ducla Soares<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Instituto de Telecomunicações<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                                                    <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Light Field HEVC-Based Image Coding Using Locally Linear Embedding and Self-Similarity Compensated Prediction<o:p></o:p></span></b></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Ricardo Monteiro<sup>1,2</sup>, Luis Lucas<sup>1,5</sup>, Caroline Conti<sup>1,2</sup>, Paulo Nunes<sup>1,2</sup>, Nuno Rodrigues<sup>1,3</sup>, Sérgio Faria<sup>1,3</sup>, Carla Pagliari<sup>4</sup>, Eduardo Silva<sup>5</sup>, Luís Ducla Soares<sup>1,2</sup><o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Instituto de Telecomunicações<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Universidade de Lisboa<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">3</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Politécnico de Leiria<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">4</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Instituto Militar de Engenharia<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">5</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Universidade Federal do Rio de Janeiro<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                                                    <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">High Efficiency Coding of Light Field Images Based on Tiling and Pseudo-Temporal Data Arrangement<o:p></o:p></span></b></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Cristian Perra<sup>1</sup>, Pedro Assuncao<sup>2</sup><o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">University of Cagliari<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Instituto de Telecomunicacoes<o:p></o:p></span></i></p>
                                                <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                                                    <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Compression of Unfocused Plenoptic Images Using a Displacement Intra Prediction<o:p></o:p></span></b></p>
                                                <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                                                    <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Yun Li, Roger Olsson, Mårten Sjöström,
                                    <span style="line-height:1.5;font-size:1em">
                                                    <span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;mso-fareast-font-family:PMingLiU;color:#505050;mso-font-kerning:
0pt;mso-ansi-language:EN-US;mso-fareast-language:ZH-TW;mso-bidi-language:AR-SA">Mid Sweden University</span></span></span></i></p>
            </span>

                                                <p>
                                                    Light field images capture information about the intensity of light in a scene and also information about the direction of the light rays in space. They are acquired with a light field camera typically corresponding to an array of micro-lenses placed in front of an otherwise conventional image sensor. In recent years, light-field cameras have become commercially available. However, an efficient compression format for this new modality does not exist yet. This challenge solicits contributions that demonstrate efficient compression of light field image data. Moreover, new evaluation methodologies are sought. Furthermore, additional publicly accessible light-field images along with evidence for compression efficiency as well as other attractive features are also accepted.
                                                <p>Please see the challenge web site for further information on the data sets, evaluation and submission procedure, <a href=" http://mmspg.epfl.ch/ICME2016GrandChallenge" target="_blank"> Light-Field Image Compression</a>. Any questions about the challenge itself should be directed to the challenge organizers.</p>

                                            </div>
                                        </div>
                                    </span>




            <span style="line-height:1.5;font-size:1em">
                <div class="auto-style1">
                    <div class="  textBox" style="">
                        <h3 id="challenge-description">2. bitmovin Grand Challenge on Dynamic Adaptive Streaming over HTTP</h3>

                        <h4 style="text-align: justify;" id="Organizers">Challenge Organizer: Christopher Müller (icme2016@bitmovin.com)</h4>
                                    <span style="line-height:1.5;font-size:1em">
                                                
                                                <p style="font-weight: 700">Time: 17:00-18:00, Tuesday, July 12, 2016
                                                 <br />Room: Grand III
                                                </p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">An Adaptative Bitrate Algorithm for Dash<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Yunlong Li<sup>1</sup>, Yue Wang<sup>1</sup>, Shanshe Wang<sup>1</sup>, Siwei Ma<sup>1,2</sup><o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Peking University<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Peking University Shenzhen Graduate School<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Buffer-based Control Theoretic Approach for Dynamically HTTP Streaming<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Zhimin Xu<sup>1,2</sup>, Chao Zhou<sup>1</sup>, Li Liu<sup>1</sup>, Xinggong Zhang<sup>1,3</sup>, Zongming Guo<sup>1,3<o:p></o:p></sup></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Peking University<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Beijing University of Posts &amp; Telecommunications<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">3</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Cooperative Medianet Innovation Center<sup><o:p></o:p></sup></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">A Bio-Inspired Http-Based Adaptive Streaming Player<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Yusuf Sani<sup>1</sup>, Andreas Mauthe<sup>1</sup>, Christopher Edwards<sup>1</sup>, Mu Mu<sup>2</sup><o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Lancaster Uuniversity<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">The University of Northampton<o:p></o:p></span></i></p>
                                    </span>




                        <p>Real-time entertainment services such as streaming video and audio are currently accounting for more than 60% of the Internet traffic during peak hours. Interestingly, these services are all delivery over-the-top (OTT) of the existing networking infrastructure using the Hypertext Transfer Protocol (HTTP) which resulted in the standardization of MPEG Dynamic Adaptive Streaming over HTTP (DASH). The MPEG-DASH standard enables smooth multimedia streaming towards heterogeneous devices and commonly assumes the usage of HTTP-URLs to identify the segments available for the clients. The MPEG-DASH standard provides an interoperable representation format but deliberately does not define the adaptation behaviour within the client implementations that is left open for research and industry competition. In a typical deployment, the encoding itself is optimised for the respective delivery channels but - as the content is delivery over the top of existing networks without any guarantees - various issues during the streaming (e.g., low startup delay, stalls/re-buffering, high switching frequency, inefficient network utilisation, competing network traffic, network infrastructure costs, etc. etc. etc.) may limit the Quality of Experience (QoE) as perceived by the end user. The aim of this grand challenge is to solicit contributions addressing end-to-end delivery aspects which improve the QoE while optimally utilising the available network infrastructures and its associated costs. This includes the content preparation for DASH, the content delivery within existing networks, and the client implementations.</p>
                        <p>Please see the challenge web site for further information on the data sets, evaluation and submission procedure, Dynamic Adaptive Streaming over HTTP <a href= "http://bitmovin.com/icme2016grandchallange" target="_blank">bitmovin Grand Challenge</a>. Any questions about the challenge itself should be directed to the challenge organizer.</p> 
                        </div>
                    </div>
                </div>
            </span>

            <span style="line-height:1.5;font-size:1em">
                <div class="auto-style1">
                    <div class="  textBox" style="">
                        <h3 id="challenge-description">3. MSR Image Recognition Challenge </h3>

                        <h4 style="text-align: justify;" id="Organizers">Challenge Organizers: Yuxiao Hu (yuxhu@microsoft.com), Lei Zhang (leizhang@microsoft.com)</h4>




            <span style="line-height:1.5;font-size:1em">
                                                
                                                <p style="font-weight: 700">Time: 10:00-11:40, Wednesday, July 13, 2016
                                                 <br />Room: Grand III
                                                </p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Deep Multi-Context Network for Fine-Grained Visual Recognition</span> </b><b style="mso-bidi-font-weight:
normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;
color:#505050;mso-font-kerning:0pt"><o:p></o:p></span></b>
                        </p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Xinyu Ou<sup>1,2,3</sup>, Zhen Wei<sup>2,4</sup>, Hefei Ling<sup>1</sup>, Si Liu<sup>2</sup>, Xiaochun Cao<sup>2 <o:p></o:p></sup></span></i>
                        </p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Huazhong University of Science and Technology<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Chinese Academy of Science<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">3</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Yunnan Open University<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">4</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">University of Electronic Science and Technology of China<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Ensemble Deep Neural Networks for Domain-Specific Image Recognition<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Wenbo Li, Chuan Ke<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Chinese Academy of Science<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Improve Dog Recognition by Mining More Information from Both Click-through Logs and Pre-Trained Models<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Guotian Xie<sup>1</sup>, Kuiyuan Yang<sup>2</sup>, Yalong Bai<sup>3</sup>, Min Shang<sup>4</sup>, Yong Rui<sup>2</sup>, Jianhuang Lai<sup>1</sup><o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">1</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Sun Yat-Sen University<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">2</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Microsoft Research<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">3</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Harbin Institute of Technology<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><sup><span style="font-size:11.0pt;
font-family:&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">4</span></sup><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Tsinghua University<o:p></o:p></span></i></p>
                        <p class="auto-style2" style="mso-para-margin-top: .5gd; mso-para-margin-right: 0in; mso-para-margin-bottom: 0in; mso-para-margin-left: 0gd; mso-para-margin-bottom: .0001pt; text-justify: inter-ideograph;">
                            <b style="mso-bidi-font-weight:normal"><span style="font-size:11.0pt;font-family:&quot;Arial&quot;,sans-serif;color:#505050;
mso-font-kerning:0pt">Learning to Recognition from Bing Clickture Data<o:p></o:p></span></b></p>
                        <p class="auto-style2" style="mso-para-margin-left: 0gd; text-justify: inter-ideograph;">
                            <i style="mso-bidi-font-style:normal"><span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;color:#505050;mso-font-kerning:0pt">Chenghua Li, Qiang Song, Yuhang Wang, Hang Song, Qi Kang, Cheng Jian, Hanqing Lu<o:p>,

            <span style="line-height:1.5;font-size:1em">
                            <span style="font-size:11.0pt;font-family:
&quot;Arial&quot;,sans-serif;mso-fareast-font-family:PMingLiU;color:#505050;mso-font-kerning:
0pt;mso-ansi-language:EN-US;mso-fareast-language:ZH-TW;mso-bidi-language:AR-SA">Chinese Academy of Science</span></span></o:p></span></i></p>
            </span>

                        <p>Thanks to the advance of deep learning algorithms, great progresses have been made in visual recognition in the past several years. But, there is still a big gap from these academic innovations and practical intelligent services, due to the lack of: (1) real-world large scale data with better quality for training and evaluation; and (2) a public platform to conduct fair, efficient evaluations and make the recognition result reproducible and accessible. To further motivate and challenge the academic and industrial research community, Microsoft has released Clickture, a large-scale real-world image click data to public, based on search engine log. The dataset contains 40M images labelled with query terms and click counts, which can be used to train and evaluate both image recognition and retrieval algorithms. Moreover, Microsoft Research has developed Prajna Hub, an open multimedia gateway, to convert latest algorithms into online services that can be accessed by anybody, from anywhere, and make the evaluation/test results reproducible and comparable. By participating in this challenge, you can:<br/>
                        * Leverage “unlimited” click data to mine and model semantics<br/>
                        * Try out your image recognition system using real world data<br/>
                        * See how it compares to the rest of the community’s entries<br/>
                        * Get to be a contender for the ICME 2016 Grand Challenge<br/>
                            </p>
                            <p>Please see the challenge web site for further information on the data sets, evaluation and submission procedure, Image Recognition Challenge <a href ="http://research.microsoft.com/en-US/projects/irc/icme2016.aspx"> MSR Image Recognition Challenge</a>. Any questions about the challenge itself should be directed to the challenge organizer.</p>
                        <div class="auto-style1">In order to see the important dates, click <a href="important-dates.html">here</a>.
                        </div>
                    </div>
                </div>
            </span>



</td></tr></tbody></table>
                </div>
                    <div id="sites-canvas-bottom-panel">
                <div xmlns="http://www.w3.org/1999/xhtml" id="COMP_page-subpages"> </div>
                <div id="sites-attachments-container">
                </div>
            </div>
    </div></body>

<!-- Mirrored from www.icme2014.org/call-for-papers by HTTrack Website Copier/3.x [XR&CO'2014], Thu, 03 Jul 2014 11:51:40 GMT -->
</html>
