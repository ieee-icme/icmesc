<?php
include 'include.php';
echoStart();
?>

<h1>Plenary Talks</h1>

<table width="95%" border="0">
   <tr>
    <td width="15%" valign="top"><a name="keyva"></a><p><a href="http://ibug.doc.ic.ac.uk/maja/"><img src="images/Maja-Dec14.jpg" width="140" height="180" /></a></p></td>
    <td width="85%"><p><strong>Title</strong>: <span class="indented highlighted">Automatic Analysis of Facial Behaviour</span><br>
<strong>Date/Time</strong>: <span class="indented highlighted">June 30, 9:00-10:00</span><br>
<strong>Room</strong>: <span class="indented highlighted">Cavour</span><br>
<strong>Slides</strong>: <span class="indented highlighted">pdf</span></p>

    </td>
    
</tr>
  <tr>
    <td colspan="2">
    <p align="justify"><strong>Abstract</strong>: Human face is our preeminent means to identify the other members of our species and communicate affective and social signals. This talk
summarises a number of aspects of human face and facial behavior and
how they can be automatically sensed and analysed by computers. Past
research in the field conducted by the iBUG group
at Imperial College London and how far are we from enabling computers
to detect, track and recognise human face and facial expressions is
discussed in detail.
More info on the work of the iBUG group can be found at
http://ibug.doc.ic.ac.uk/home.  For databases and software solutions
to various problems in the field of automatic facial expression
analysis, see
http://ibug.doc.ic.ac.uk/resources. More info on Maja Pantic can be
found at http://ibug.doc.ic.ac.uk/~maja</p></td>
  </tr>
  <tr>
    <td colspan="2">
      <p align="justify"><strong>Maja Pantic</strong> obtained her PhD degree in computer science in 2001 from
Delft University of Technology, the Netherlands. Until 2005, she was
an Assistant/ Associate Professor at Delft University of Technology.
In 2006, she joined the Imperial College London, Department of
Computing, UK, where she is Professor of Affective & Behavioural
Computing and the Head of the iBUG group, working on machine analysis
of human non-verbal behaviour. From November 2006, she also holds an
appointment as the Professor of Affective & Behavioural Computing at
the University of Twente, the Netherlands.</p>
<p align="justify">
She received a number of prestigious awards including the ERC Starting
Grant, awarded to 2% best young scientists in Europe in 2007, and the
BCS Roger Needham Award in 2011, awarded annually to the UK based
researcher for a distinguished research contribution in Computer
Science within ten years of their PhD. She
has published over 150 articles, won several Best Paper awards, and
served as Editor in Chief and Associate
Editor in all major journals in her field including IEEE Trans. PAMI.
She is an IEEE Fellow.</p>
      </td>
  </tr>
  <tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
  <tr>
    <td valign="top"><a name="keyza"></a><p><a href="https://users.soe.ucsc.edu/~milanfar/"><img src="images/payman1.jpg" width="170" height="180" /></a></p></td>
    <td><p><strong>Title</strong>: <span class="indented highlighted">Computational Imaging: From Photons to Photos</span><br>
<strong>Date/Time</strong>: <span class="indented highlighted">July 1, 9:00-10:00</span><br>
<strong>Room</strong>: <span class="indented highlighted">Cavour</span><br>
<strong>Slide set</strong>:  <span class="indented highlighted"><a href="slides/ICME_PlenaryMilanfar.pdf">PDF (46Mb)</a></span><br>
</p>
    </td></p>

</tr>
  <tr>
    <td colspan="2">
    <p align="justify"><strong>Abstract</strong>: Fancy cameras used to be the exclusive domain of professional photographers and experimental scientists. Times have changed, but even as recently as a decade ago, consumer cameras were solitary pieces of hardware and glass; disconnected gadgets with little brains, and no software. But now, everyone owns a smartphone with a powerful processor, and every smartphone has a camera. These mobile cameras are simple, costing only a few dollars per unit. And on their own, they are no competition for their more expensive cousins. But coupled with the processing power native to the devices in which they sit, they are so effective that much of the low-end point-and-shoot camera market has already been decimated by mobile photography.</p>

<p align="justify">Computational imaging is the enabler for this new paradigm in consumer photography. It is the art, science, and engineering of producing a great shot (moving or still) from small form factor, mobile cameras. It does so by changing the rules of image capture — recording information in space, time, and across other degrees of freedom — while relying heavily on post-processing to produce a final result. Ironically, in this respect, mobile imaging devices are now more like scientific instruments than conventional cameras. This has deep implications for the future of consumer photography.</p>

<p align="justify">In this technological landscape, the ubiquity of devices and open platforms for imaging will inevitably lead to an explosion of technical and economic activity, as was the case with other types of mobile applications. Meanwhile, clever algorithms, along with dedicated hardware architectures, will take center stage and enable unprecedented imaging capabilities in the user’s hands.</p></td>
  </tr>
  <tr>
    <td colspan="2">
      <p align="justify"><strong>Peyman Milanfar</strong> received his undergraduate education in electrical engineering and mathematics from the University of California, Berkeley, and the MS and PhD degrees in electrical engineering from the Massachusetts Institute of Technology. He has been on the EE faculty at UC Santa Cruz since 1999, having served as Associate Dean of the School of Engineering from 2010-12. Since 2012 he has been at Google-x, and Google Research, where he was recruited to work on computational photography and more specifically, on the imaging pipeline for Google Glass. He currently leads the computational imaging effort in Google Research. He is a Fellow of the IEEE.</p>
    </td>
  </tr>
<tr>
    <td>&nbsp;</td>
    <td>&nbsp;</td>
  </tr>
 <tr>
    <td width="15%" valign="top"><a name="keybl"></a><p><a href="http://yima.csl.illinois.edu"><img src="images/yima.jpg" width="125" height="140" /></a></p></td>
    <td><p><strong>Title</strong>: <span class="indented highlighted">Pursuit of Low-dimensional Structures in High-dimensional Data</span><br>
<strong>Date/Time</strong>: <span class="indented highlighted">July 2, 9:00-10:00</span><br>
<strong>Room</strong>: <span class="indented highlighted">Cavour</span><br>
<strong>Slide set</strong>:  <span class="indented highlighted"><a href="slides/Low-Dim-ICME.pdf">PDF (46Mb)</a></span><br>
</p>
    </td></tr>
  <tr>
    <td colspan="2">
    <p align="justify"><strong>Abstract</strong>: In this talk, we will discuss a new class of models and techniques that can effectively model and extract rich low-dimensional structures in high-dimensional data such as images and videos, despite nonlinear transformation, gross corruption, or severely compressed measurements. This work leverages recent advancements in convex optimization for recovering low-rank or sparse signals that provide both strong theoretical guarantees and efficient and scalable algorithms for solving such high-dimensional combinatorial problems. These results and tools actually generalize to a large family of low-complexity structures whose associated regularizers are decomposable. We illustrate how these new mathematical models and tools could bring disruptive changes to solutions to many challenging tasks in computer vision, image processing, and pattern recognition. We will also illustrate some emerging applications of these tools to other data types such as web documents, image tags, microarray data, audio/music analysis, and graphical models. </p>

<p>This is joint work with John Wright of Columbia, Emmanuel Candes of Stanford, Zhouchen Lin of Peking University, and my students Zhengdong Zhang, Xiao Liang of Tsinghua University, Arvind Ganesh, Zihan Zhou, Kerui Min and Hossein Mobahi of UIUC.
</p></td>
  </tr>
  <tr>
    <td colspan="2">
 
      <p align="justify"><strong>Yi Ma</strong> is a Professor and the Associate Dean of the School of Information and Science and Technology, ShanghaiTech University, China. From 2009 to early 2014, he was a Principal Researcher and the Research Manager of the Visual Computing group at Microsoft Research in Beijing. From 2000 to 2011, he was an Associate Professor at the Electrical & Computer Engineering Department of the University of Illinois at Urbana-Champaign. His main research interest is in computer vision, high-dimensional data analysis, and systems theory. He is the first author of the popular vision textbook “An Invitation to 3-D Vision," published by Springer in 2003. Yi Ma received his Bachelors’ degree in Automation and Applied Mathematics from Tsinghua University (Beijing, China) in 1995, a Master of Science degree in EECS in 1997, a Master of Arts degree in Mathematics in 2000, and a PhD degree in EECS in 2000, all from the University of California at Berkeley. Yi Ma received the David Marr Best Paper Prize at the International Conference on Computer Vision 1999, the Longuet-Higgins Best Paper Prize at the European Conference on Computer Vision 2004, and the Sang Uk Lee Best Student Paper Award with his students at the Asian Conference on Computer Vision in 2009. He also received the CAREER Award from the National Science Foundation in 2004 and the Young Investigator Award from the Office of Naval Research in 2005. He was an associate editor of IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) from 2007 to 2011. He is currently an associate editor of the International Journal of Computer Vision (IJCV), the IMA journal on Information and Inference, SIAM journal on Imaging Sciences, and IEEE transactions on Information Theory. He has served as the chief guest editor for special issues for the Proceedings of IEEE and the IEEE Signal Processing Magazine. He served as a Program Chair for ICCV 2013 and will be a General Chair for ICCV 2015. He is a Fellow of IEEE.</p>
      </td>
  </tr>
</table>

<br />
<br />
<br />


<?php
echoEnd();
?>