<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<html>
  <head>
    <title>ICME 2006</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <link rel="stylesheet" type="text/css" href="CommonFiles/icme2006.css">

    <style type="text/css" media="print">
<!--
    #MenuBlock { display: none; }
    #ContentBlock { margin-left: 1em; }
-->
    </style>
  </head>
  <body>
<div id="HeaderBlock"><img src="images/ICME2006-WebHeader.gif" alt="ICME 2006 Toronto"></div>
<div id="columnContainer">
<div id="MenuBlock"><div id="MenuBlock-content">
  <ul id="navigation">
    <li><a href="default.asp">Home</a></li>
    <li><a href="CallForPapers.asp">Call for Papers</a></li>
    <li><a href="ImportantDates.asp">Important Dates</a></li>
    <li><a href="Keynotes.asp">Keynote Talks</a></li>
    <li><a href="Papers.asp">Paper Submission</a></li>
    <li><a href="RegularProgram.asp">Technical Program</a></li>
    <li><a href="Registration.asp">Registration</a></li>
    <li><a href="MeetingSchedule.asp">Meeting Schedule</a></li>
    <li><a href="Housing.asp">Accommodation</a></li>
    <li><a href="SpecialSessions.asp">Special Sessions</a></li>
    <li><a href="Tutorials.asp">Tutorials</a></li>
    <li><a href="SocialEvents.asp">Social Events</a></li>
    <li><a href="Venue.asp">Venue</a></li>
    <li><a href="AboutToronto.asp">About Toronto</a></li>
    <li><a href="TechnicalCommittee.asp">Technical Program Committee</a></li>
    <li><a href="OrganizingCommittee.asp">Organizing Committee</a></li>
    <li><a href="SponsorSupport.asp">Sponsors</a></li>
  </ul>
</div></div>
<div id="ContentBlock"><div id="ContentBlock-content"><!-- End Header -->


<h1>Interactive Multimedia Content Analysis and Applications</h1>

<div class="SpecialSessionCfP">

<h2>Organizers</h2>

<table>
  <tr><td>Xian-Sheng Hua<br>
  Microsoft Research Asia<br>
  xshua@microsoft.com<br></td></tr>
  <tr><td>Qi Tian<br>
  University of Texas at San Antonio<br>
  qitian@cs.utsa.edu<br></td></tr>
</table>

<h2>Call for Papers</h2>

<p>With the explosive growth of digital media data, there is a huge demand for new tools and systems that enables average users to more efficiently and more effectively search, access, process, manage, author and share these digital media contents.</p>

<p>Automatic content analysis techniques are widely applied to extract metadata and annotate videos aiming at describing the content of videos at both syntactic and semantic levels.  With the help of these metadata, tools and systems for video retrieval, summarization, delivery and manipulation can be created effectively.</p>

<p>However, great difficulties are encountered in automatically bridging the large gap between high-level semantics (what we expect) and low-level features (what we can obtain).  The results of automatic video annotation techniques are far from satisfactory due to this gap as well as the lack of training data compared with the large variations of the semantic concepts in images and videos that are desired to be modeled. While at the same time, manual annotation is not only labor-intensive and time-consuming, but also subjects to human errors.  To tackle this difficulty, relevance feedback is considered to be an effective method to narrow down this gap when doing retrieval.  And, to accelerate the convergence speed of learning process, several active learning schemes, in which the most informative samples are chosen to be labeled, have been proposed.</p>

<p>Enlightened by these promising approaches, can we achieve much better content analysis results after introducing users’ interaction in a wider space?  These interactions could be introduced into different steps during the lifecycle of multimedia data, including media content acquisition, modeling, annotation, sharing, authoring, etc.  For example, for personal media, could we passively and/or actively get more useful information during the acquisition, browsing, editing and sharing process so we may obtain better content analysis results?  Can the training process be more effective and efficient if user provides some inputs?  Will the data distribution be better estimated after getting feedback from users?  Will the classification accuracy be greatly improved after a limited round of interactions? Of course, one thing we need to take into account is that we should try to minimize users’ interaction during these processes while at the same time maximize what we can obtain.</p>

<p>Furthermore, as more and more media data is available on the Web, could we design appropriate tools based on content analysis and contextual analysis that enable super efficient interactive media annotation?</p>

<p>This special session could include papers on the following or related topics:</p>

<ul>
  <li>Interactive multimedia data modeling</li>
  <li>Interactive multimedia clustering, classification and annotation, such as relevant feedback and active learning for large-scale multimedia repository.</li>
  <li>Multimedia applications based on interactive multimedia content analysis, or interactive applications based automatic or interactive content analysis.</li>
  <li>Content analysis and/or applications based on interactive multimedia acquisition.</li>
  <li>Learning from users’ interactive behavior histories on multimedia data.</li>
</ul>

</div>

<div style="height: 1em;"></div>
<!-- Begin Footer --></div></div>
<hr class="cleaner" />
<div id="FooterBlock">
  <p>&copy;2014 <a href="http://www.cmsworldwide.com/">Conference Management Services, Inc.</a> -||- email: <a href="mailto:webmaster@icme2006.org">webmaster@icme2006.org</a> -||- Last updated Friday, January 13, 2006</p>
</div>
  </body>
</html>
