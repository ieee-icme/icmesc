<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN" "http://www.w3.org/TR/html4/loose.dtd">

<html>
  <head>
    <title>ICME 2006</title>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    <link rel="stylesheet" type="text/css" href="CommonFiles/icme2006.css">

    <style type="text/css" media="print">
<!--
    #MenuBlock { display: none; }
    #ContentBlock { margin-left: 1em; }
-->
    </style>
  </head>
  <body>
<div id="HeaderBlock"><img src="images/ICME2006-WebHeader.gif" alt="ICME 2006 Toronto"></div>
<div id="columnContainer">
<div id="MenuBlock"><div id="MenuBlock-content">
  <ul id="navigation">
    <li><a href="default.asp">Home</a></li>
    <li><a href="CallForPapers.asp">Call for Papers</a></li>
    <li><a href="ImportantDates.asp">Important Dates</a></li>
    <li><a href="Keynotes.asp">Keynote Talks</a></li>
    <li><a href="Papers.asp">Paper Submission</a></li>
    <li><a href="RegularProgram.asp">Technical Program</a></li>
    <li><a href="Registration.asp">Registration</a></li>
    <li><a href="MeetingSchedule.asp">Meeting Schedule</a></li>
    <li><a href="Housing.asp">Accommodation</a></li>
    <li><a href="SpecialSessions.asp">Special Sessions</a></li>
    <li><a href="Tutorials.asp">Tutorials</a></li>
    <li><a href="SocialEvents.asp">Social Events</a></li>
    <li><a href="Venue.asp">Venue</a></li>
    <li><a href="AboutToronto.asp">About Toronto</a></li>
    <li><a href="TechnicalCommittee.asp">Technical Program Committee</a></li>
    <li><a href="OrganizingCommittee.asp">Organizing Committee</a></li>
    <li><a href="SponsorSupport.asp">Sponsors</a></li>
  </ul>
</div></div>
<div id="ContentBlock"><div id="ContentBlock-content"><!-- End Header -->


<h1>T2.3: Music Information Retrieval</h1>

<p><strong>Sunday, July 9, 2006 (13:30 - 16:30, Varley)</strong></p>

<h4>Instructor</h4>

<p><a href="http://www.cs.uvic.ca/gtzan">Professor George Tzanetakis</a>, <em>University of Victoria, Canada</em></p>

<h4>Abstract</h4>

<p>Music has always been profoundly transformed by advances in technology.
Examples of such transformations include the use of music notation, the
invention of recording and more recently digital music storage and
distribution. Portable music players such as Apple’s iPods can today store
thousands of songs and online music sales have been steadily increasing. It is
likely that in the near future anyone will be able to access digitally all of
recorded music in human history. In order to efficiently interact with these
large collections of music it is necessary to develop tools that have some
understanding of the actual musical content. Music Information Retrieval (MIR)
is an emerging research discipline that deals with all aspects of organizing
and extracting information from music. Interest in MIR has been steadily
increasing as can be evidenced by the numbers of MIR-related papers in ICME,
ICASSP and other conferences as well as the sixth year existence of ISMIR which
is a conference solely focused on MIR. In this tutorial, an overview of the
current state of the art in MIR with special emphasis on the use of signal
processing and machine learning techniques will be provided. Many of the
techniques used in MIR have their roots in more traditional areas such as
Speech Recognition, Psycoacoustics and Audio Compression. However music has
several unique characteristics which have led researchers to develop
music-specific signal processing methods.</p>

<h4>Course Outline</h4>

<p>The tutorial will be roughly divided between the following topics. The provided times are approximate and connections will be made between the ideas in each topic.</p>

<p><strong>I. History and Overview of Music, Information Retrieval and Music Information Retrieval</strong><br>
A quick introduction to the fundamentals of music, information retrieval (MIR) followed by a general overview of the history and current state of the art in MIR both in academia and industry.</p>

<p><strong>II. Audio Feature Extraction</strong><br>
Audio feature extraction forms the basis of most algorithms that extract content information from music signals in audio format. Specifics topics covered include: Short Time Fourier Transform, Wavelets, Perceptually-motivated filterbanks, Linear Prediction, Audio compression with specific emphasis on how they are applied to the processing of music signals.</p>

<p><strong>III. Content-based Similarity Retrieval, Segmentation and Classification</strong><br>
Content-based similarity retrieval enables music to be searched based on how it sounds rather than metadata such as the artist or the album. The automatic classification of music into genres, styles and moods will also be covered. Segmentation is the process of locating changes of “texture” in music. Different approaches to segmentation such as abrupt-change detection, hidden-markov modeling and use of the similarity matrix will be covered.</p>

<p><strong>IV. Music-specific Processing</strong><br>
Although initial work in Music Information Retrieval (MIR) mainly used ideas and features from Speech Analysis, a recent trend has been to develop music-specific feature extraction and analysis algorithms. Examples include: tempo induction, rhythm representations, pitch-content representations, structural analysis and polyphonic score and audio alignment.</p>

<p><strong>V. Query-by-humming</strong><br>
In query-by-humming the user sings or hums a melody to the computer which then searches a database of music material for finding the corresponding score or audio recording. This challenging problem combines robust pitch extraction and segmentation, complex approximate string matching techniques and efficient database searching.</p>

<p><strong>VI. Fingerprinting &amp; Watermarking</strong><br>
Audio fingerprinting is the process of extracting a digital signature based on audio content that uniquely characterizes a specific piece of music independently of its playback medium and audio compression. It can be used for copyright protection, linking
songs with metadata and identifying unknown pieces of music. Audio watermarking is the process of embedding additional information into a piece of music by modifying the actual audio signal in such a way that changes are not perceived by our ears. Techniques and audio features that have been proposed for fingerprinting and watermarking will be described.</p>

<p><strong>VII. Content-Aware User Interfaces</strong><br>
Various interesting user interfaces have been proposed for visualizing, browsing and interacting with collections of audio and music signals. The most interesting ones use directly the results of content-analysis to inform their appearance and interaction with the user.</p>

<p><strong>VIII. Challenges and connections to other research areas</strong><br>
MIR is a new emerging research area and there are many challenges for the future. One of the most important is the problem of identifying and characterizing multiple sound sources in a mixture. Robust speech recognition and auditory scene analysis are examples of areas that would benefit from progress in this problem. </p>

<p>Audio-Visual equipment and materials will be provided to attendees including a laptop projector and an audio system for playing audio examples. Participants will be provided with handouts of the tutorial slides, pointers to online resources and software, an annotated bibliography of approximately 200 papers, and an MIR overview paper covering the topics of the tutorial (approximately 20-30 pages).</p>

<h4>Speaker Biography</h4>

<p><strong>George Tzanetakis</strong> is an assistant Professor of Computer
Science at the University of Victoria (also cross-listed in Music). He received
his PhD degree in Computer Science from Princeton University in May 2002 and
was a Post-Doctoral Fellow at Carnegie Mellon University working on
query-by-humming systems with Prof. Dannenberg and on video and audio retrieval
with the Informedia group. In addition he was chief designer of the audio
fingerprinting technology of Moodlogic Inc., and developed a real-time music
speech classification system for All Music Publishing, The Netherlands. His
research deals with all stages of audio content analysis such as feature
extraction, segmentation, classification with specific focus on Music
Information Retrieval (MIR). His work on musical genre classification is
frequently cited and received the IEEE Signal Processing Society Young Author
Award in 2004. He has presented tutorials on MIR and audio feature extraction
at several international conferences. He is associate editor of Computer Music
Journal and of the IEEE Transactions on Speech and Audio Processing. He is also
an active musician and has studied saxophone performance, music theory and
composition.</p>

<div style="height: 1em;"></div>
<!-- Begin Footer --></div></div>
<hr class="cleaner" />
<div id="FooterBlock">
  <p>&copy;2014 <a href="http://www.cmsworldwide.com/">Conference Management Services, Inc.</a> -||- email: <a href="mailto:webmaster@icme2006.org">webmaster@icme2006.org</a> -||- Last updated Friday, June 23, 2006</p>
</div>
  </body>
</html>
