<?php
include 'include.php';
echoStart();
?>
<h1>Tutorials</h1>

<h2>Schedule</h2>
<h4 style="margin-left:0px">Monday July 15 morning</h4>
<p align="justify">
<a href="#tuthigh">High Efficiency Video Coding – Coding Tools and Specification</a> (Room: Piedmont)<br />
<a href="#tutsocial">Social Multimedia Signals: When Social Networking Meets Signal Processing</a> (Room: Gold)<br />
<a href="#tutactive">Active Learning for Multimedia Content Analysis</a> (Room: Garden)</p>

<h4 style="margin-left:0px">Monday July 15 afternoon</h4>
<p align="justify">
<a href="#tuthttp">HTTP Adaptive Streaming: Principles, Ongoing Research and Standards</a> (Room: Piedmont)<br />
<a href="#tutdev">Development of Coding Tools from 2D to Depth-Enhanced 3D Video Compression</a> (Room: Gold)<br />
<a href="#tutfrom">From Imaging Data to Useful Visual Information</a> (Room: Garden)</p>

<h4 style="margin-left:0px">Friday July 19 morning</h4>
<p align="justify">
<a href="#tutsignal">Signal Processing Methods for Stereoscopic and Multi-View 3D Displays</a> (Room: Gold)<br />
<a href="#tutonline">Online Learning for Real-Time Multimedia</a> (Room: Garden)<br />
<a href="#tutpercep">Perceptual Coding of Digital Pictures</a> (Room: Crystal)</p>

<br />
<br />
<br />
<h2><a name="tuthigh"></a>High Efficiency Video Coding – Coding Tools and Specification</h2>
<p><strong>Date/Time</strong>: Monday July 15 morning</p>
<p><strong>Room</strong>: Piedmont</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://www.ient.rwth-aachen.de/cms/wien/" target="_blank">Mathias Wien</a></span>, RWTH Aachen University, Germany<br /></p>
<table width="125" border="0">
  <tr>
    <td><img src="images/tutorial/mathiaswien.jpg" width="125" height="180" alt="Mathias Wien" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">The tutorial provides an overview on the new video coding standard HEVC (High Efficiency Video Coding) jointly published by ITU-T and ISO/IEC as ITU-T H.265 and ISO/IEC 23008-2, respectively. HEVC has been developed with a focus on high definition and ultra high definition video resolutions. Besides improved coding efficiency, the main design criteria in the development phase of HEVC were low computational complexity and friendliness for parallelization on various algorithmic levels. Simulations with the HEVC test model software HM reportedly reveal rate savings of about 50% compared to the established video coding standard H.264/AVC at the same visual quality. The tutorial reviews in detail the video layer coding tools and develops the concepts behind the selected design choices. It provides thorough overview on the high-level syntax and discusses the design in many illustrative examples. While many tools or variants thereof have been available before, the HEVC design reveals many improvements compared to previous standards which result in compression gain and implementation friendliness. The tutorial provides insight into the mechanisms that contribute to the observed improvements.</p>

<br />
<br />
<br />
<h2><a name="tutsocial"></a>Social Multimedia Signals: When Social Networking Meets Signal Processing</h2>
<p><strong>Date/Time</strong>: Monday July 15 morning</p>
<p><strong>Room</strong>: Gold</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://people.cs.missouri.edu/~zengw" target="_blank">Wenjun Zeng</a></span>, University of Missouri, USA<br />
<span class="highlighted"><a href="http://web.missouri.edu/~sdr5x8" target="_blank">Suman D. Roy</a></span>, University of Missouri, USA</p>
<table width="275" border="0">
  <tr>
    <td><img src="images/tutorial/wenjunzeng.jpg" width="125" height="180" alt="Wenjun Zeng" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/sumanroy.jpg" width="125" height="180" alt="Suman D. Roy" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">Social Multimedia refers to media content generated from social networks. A Social Multimedia Signal presumes human users as sensors and contains the spatio-temporal activity pattern of users (or user community) with respect to some multimedia content shared within the social network. Since social data is inherently noisy, it is still uncertain as to what are the best practices to separate the signal from the noise in multimedia obtained from online social networks. Social Multimedia Signal Processing aims to transform the noise-like phenomena in social media into signals useful for building novel socially-aware multimedia applications such as cross-domain media recommendations and targeted advertising, exploring new social marketing methods and a fresh way to look at the existence of multimedia in online social networks.</p>

<p align="justify">The tutorial intends to provide a comprehensive coverage of the state-of-the-art in understanding media popularity and trends in online social networks through social multimedia signals. Audience will learn insights from the study of popularity and sharing patterns of online media, trend spread in social media, social network analysis for multimedia and visualizing diffusion of media in online social networks. In particular, the tutorial highlights two interesting aspects of shared media in social networks - its context and its popularity over lifetime and how we can predict both these quantitatively using the signal generated from the concerned media.</p>

<p align="justify">The tutorial is divided into three parts, focusing on: (1) Social Multimedia Signal Detection and Estimation, (2) Social Multimedia Signal Drifts and spatio-temporal trajectory, and (3) Social Multimedia Signal Penetration across media platforms on the Internet.</p>

<br />
<br />
<br />
<h2><a name="tutactive"></a>Active Learning for Multimedia Content Analysis</h2>
<p><strong>Date/Time</strong>: Monday July 15 morning</p>
<p><strong>Room</strong>: Garden</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="https://sites.google.com/a/asu.edu/shayok-chakraborty/" target="_blank">Shayok Chakraborty</a></span>, Arizona State University, USA<br />
<span class="highlighted"><a href="http://www.public.asu.edu/~vnallure/" target="_blank">Vineeth Balasubramanian</a></span>, Arizona State University, USA<br />
<span class="highlighted"><a href="http://cidse.engineering.asu.edu/directory/sethuraman-panchanathan/" target="_blank">Sethuraman (Panch) Panchanathan</a></span>, Arizona State University, USA</p>
<table width="425" border="0">
  <tr>
    <td><img src="images/tutorial/shayokchakraborty.jpg" width="125" height="180" alt="Shayok Chakraborty" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/vineethbalasubramanian.jpg" width="125" height="180" alt="Vineeth Balasubramanian" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/sethuramanpanchanathan.jpg" width="125" height="180" alt="Sethuraman (Panch) Panchanathan" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">The increasing miniaturization of sensing technologies, together with their widespread use, has resulted in the generation of humongous amounts of multimedia data (in the form of images, audio and text among others) in today's world. While this has expanded the possibilities of solving real world problems (such as understanding the behavior of people, objects and activities) using computational learning frameworks, selecting the salient data samples from such huge collections of data has proved to be a significant and practical challenge. Further, to train a reliable classification model, it is indispensable to have a large quantity of labeled training data. Manual annotation of large amounts of data is an expensive process in terms of time, labor and human expertise. This has set the stage for research in the field of active learning in multimedia content analysis. Active learning algorithms automatically select the salient and exemplar instances from large quantities of unlabeled data and thereby tremendously reduce human annotation effort in training an effective classifier. Moreover, they endow the classification model with greater generalization capability, as it gets trained on the most informative samples from the underlying data population. Active learning can be applied across all existing classification methods and with any kind of data, thus making it a very generalizable approach. The success of active learning in several multimedia computing applications (such as image retrieval, text/web mining, speech processing and social network analysis) has resulted in the extension of the framework to problem settings beyond regular classification. Active learning concepts have been extended to newer problem settings like clustering, regression, feature selection and anomaly / rare category detection. This tutorial will seek to present a comprehensive overview of active learning in multimedia content analysis including historical perspectives, theoretical analysis and newer paradigms such as interactive learning, along with examples/case studies of their applications in multimedia content analysis.</p>

<br />
<br />
<br />
<h2><a name="tuthttp"></a>HTTP Adaptive Streaming: Principles, Ongoing Research and Standards</h2>
<p><strong>Date/Time</strong>: Monday July 15 afternoon</p>
<p><strong>Room</strong>: Piedmont</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://ali.begen.net/" target="_blank">Ali C. Begen</a></span>, Cisco, Canada<br />
<span class="highlighted"><a href="http://www.nomor.de/home/company/management3" target="_blank">Thomas Stockhammer</a></span>, Nomor Research, Germany</p>
<table width="275" border="0">
  <tr>
    <td><img src="images/tutorial/alibegen.jpg" width="125" height="180" alt="Ali C. Begen" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/thomasstockhammer.jpg" width="125" height="180" alt="Thomas Stockhammer" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">This tutorial consists of three parts. In the first part, we survey well-established streaming solutions for over-the-top (OTT) video delivery, explaining how OTT video delivery contrasts to traditional broadcast managed IPTV services. We then provide a detailed overview of HTTP adaptive streaming and its building blocks. We explain the workflows for content generation, distribution and consumption. Some observations and experiences from real deployments including TV Everywhere are also provided. In the second part, we review recent research findings along with a discussion of future research directions. In the third part, we describe the key standards and emerging technologies for HTTP adaptive streaming. In particular, the new ISO standard MPEG DASH, ongoing industry efforts in DASH Industry Forum and developing technologies such as eMBMS will be examined.</p>

<br />
<br />
<br />
<h2><a name="tutdev"></a>Development of Coding Tools from 2D to Depth-Enhanced 3D Video Compression
</h2>
<p><strong>Date/Time</strong>: Monday July 15 afternoon</p>
<p><strong>Room</strong>: Gold</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://iphome.hhi.de/mueller/index.htm">Karsten M&uuml;ller</a></span>, Fraunhofer HHI, Germany<br /></p>
<table width="125" border="0">
  <tr>
    <td><img src="images/tutorial/karstenmuller.jpg" width="125" height="180" alt="Karsten M&uuml;ller" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">New home entertainment systems, such as glasses-free three-dimensional television require new 3D video technology beyond stereo video For the transmission scenarios, efficient standardized compression methods are required, such as 3D video coding for depth-enhanced multi-view video formats, which is the topic of this presentation. First, the principles of recent state-of-the-art 2D video coders, as well as stereo-only and multi-view coders are reviewed. Next, generic depth-enhanced 3D video formats are presented, which are independent of the 3D display type. For such formats, the specific requirements and an evaluation framework are explained. Then new 3D video coding tools will be presented for advanced inter-view prediction in video and depth data, depth-intra coding methods for edge preservation and inter-component prediction from video to depth. For the final 3D video coder, subjective and objective results in comparison to single-view and simple multi-view coding are shown. Finally, alternative 3D representation formats are discussed, which may become subject to future coding methods and extensions.</p>

<br />
<br />
<br />
<h2><a name="tutfrom"></a>From Imaging Data to Useful Visual Information</h2>
<p><strong>Date/Time</strong>: Monday July 15 afternoon</p>
<p><strong>Room</strong>: Garden</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://www.inf.ufrgs.br/~jacobs/" target="_blank">Jacob Scharcanski</a></span>, UFRGS, Brasil<br /></p>
<table width="125" border="0">
  <tr>
    <td><img src="images/tutorial/jacobscharcanski.jpg" width="125" height="180" alt="Jacob Scharcanski" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">In this talk, we address the problem of extracting relevant information from image data. We also introduce briefly the concepts and techniques often used in the automatic interpretation of phenomena based on imagery, or to make inferences based on models of such imagery data. When modeling and representing imaging measurements, usually we are trying to describe the world (or a real world phenomenon) using one or more images, and reconstruct some of its properties based on imagery data (like shape, texture or color). Actually, this is an ill-posed problem that humans can learn to solve effortlessly, but computer algorithms often are prone to errors. Nevertheless, in some cases computers can surpass humans and interpret imagery more accurately, given the proper choice of data representations (i.e. features), as we discuss in this talk. In order to illustrate this presentation, several applications are discussed, focusing in areas such as medicine, biometrics, surveillance, human-machine interfaces, multimedia. Finally, some challenging industrial applications also are discussed.</p>


<br />
<br />
<br />
<h2><a name="tutsignal"></a>Signal Processing Methods for Stereoscopic and Multi-View 3D Displays</h2>
<p><strong>Date/Time</strong>: Friday July 19 morning</p>
<p><strong>Room</strong>: Gold</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://www.cs.tut.fi/~suncho/" target="_blank">Atanas Boev</a></span>, Tampere University of Technology, Finland<br />
<span class="highlighted"><a href="http://www.cs.tut.fi/~bregovic/" target="_blank">Robert Bregovic</a></span>, Tampere University of Technology, Finland<br />
<span class="highlighted"><a href="http://www.cs.tut.fi/~agotchev/" target="_blank">Atanas Gotchev</a></span>, Tampere University of Technology, Finland</p>
<table width="425" border="0">
  <tr>
    <td><img src="images/tutorial/atanasboev.jpg" width="125" height="180" alt="Atanas Boev" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/robertbregovic.jpg" width="125" height="180" alt="Robert Bregovic" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/atanasgotchev.jpg" width="125" height="180" alt="Atanas Gotchev" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">Displays which aim at visualizing 3D scenes with realistic depth are broadly referred to as "3D displays".  A class of such displays which create stereoscopic effect with no need of special grasses is referred to as auto-stereoscopic displays and in case of multiple parallax views created – as multi-view 3D displays. Due to technical limitations and design decisions, such displays might create visible distortions, which are interpreted by the human visual system as artifacts. The proposed tutorial overviews a number of signal processing techniques for decreasing the visibility of artifacts on 3D displays. The tutorial starts with identifying the properties of a 3D visual scene which the brain utilizes for perceiving depth. Further, operation principles of the most popular types of 3D displays are explained. Reflecting these principles, a 3D display general model in terms of signal processing channel is formulated. The model is operational for analyzing the changes in visual quality enforced by display distortions. The analysis allows identifying a set of optical properties which are directly related with the perceived quality. Methodologies for measuring these properties and creating quality profiles of 3D displays are discussed in the tutorial. A comparative study introducing measurement results on the visual quality and position of the sweet-spots of a number of 3D displays of different types is presented. Based on knowledge of 3D artifact visibility and understanding of distortions introduced by 3D displays, a number of signal processing methods for artifact mitigation are overviewed. These include methods for mitigating typical 3D display artifacts such as Moiré, fixed-pattern-noise, and ghosting. Frequency-domain analysis is specifically emphasized and the notation of display passband is introduced. This notation is utilized for introducing a framework for design of tunable anti-aliasing filters. At the end, a set of real-time algorithms for view-point based optimization are reviewed.</p>

<br />
<br />
<br />
<h2><a name="tutonline"></a>Online Learning for Real-Time Multimedia</h2>
<p><strong>Date/Time</strong>: Friday July 19 morning</p>
<p><strong>Room</strong>: Garden</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"> Fangwen Fu</span>, Intel, USA<br />
<span class="highlighted"><a href="http://www.ee.ucla.edu/people/faculty/faculty-directory/mihaela-van-der-schaar" target="_blank">Mihaela van der Schaar</a></span>, UCLA, USA</p>
<table width="275" border="0">
  <tr>
    <td><img src="images/tutorial/fangwenfu.jpg" width="125" height="180" alt="Fangwen Fu" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/mihaelavanderschaar.jpg" width="125" height="180" alt="Mihaela van der Schaar" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">Real-time multimedia applications operate in dynamic and unknown environments where they experience time-varying and a priori unknown channel and network conditions, source and traffic characteristics and/or energy, system or usage requirements. Traditional concepts and techniques used for multimedia (processing, compression, networking, systems etc.) rely on well-known optimization, learning and adaptation methods which are not successful in enabling multimedia applications to efficiently and robustly adapt at run-time to the dynamic and unknown environments which they are facing. For this, new theories, algorithms and metrics are needed to complement the classical optimization, stochastic control and learning theories.</p>

<p align="justify">In this tutorial we present a novel and unified online learning framework (including both formalisms and practical implementations) aimed at optimizing delay-critical multimedia operating in uncertain and/or dynamically-changing source, network and user environments. Using the proposed online learning framework, devices, algorithms and protocols operating in various networking environments and at various layers of the protocol stack are able to learn how to act in order to maximize their own utilities using a novel class of online (reinforcement) learning techniques that do not require a priori specified models of these environments. The online learning techniques which we will introduce are unique because they are very efficient and fast, yet general, and thus they can be easily applied to learn optimal policies online (at run-time), based on the experienced dynamics. The online learning methods presented in this tutorial can be used to optimally adapt the encoding strategies (e.g. AVC or HEVC rate control), transmission strategies at the various layers of the protocol stack (e.g. error control, scheduling, stream switching, congestion control, routing, energy-efficient processing etc.) to the various unknown and dynamic environments in which they need to operate. Importantly, the presented online learning formalisms and solutions can be simultaneously deployed at one or multiple layers of the protocol stack and they can operate in concert, to provide integrated cross-layer solutions. They can also be used in both single user as well as multi-user networking environments.</p>

<br />
<br />
<br />
<h2><a name="tutpercep"></a>Perceptual Coding of Digital Pictures</h2>
<p><strong>Date/Time</strong>: Friday July 19 morning</p>
<p><strong>Room</strong>: Crystal</p>
<p><strong>Presenters</strong></p>
<p><span class="highlighted"><a href="http://www-ee.uta.edu/EEDept/faculty/rao.htm" target="_blank">K. R. Rao</a></span>, The University of Texas at Arlington, USA<br />
<span class="highlighted"><a href="http://www.rmit.com.au/browse;ID=a256otsusiyp" target="_blank">Hong Ren Wu</a></span>, Royal Melbourne Institute of Technology, Australia</p>
<table width="275" border="0">
  <tr>
    <td><img src="images/tutorial/krrao.jpg" width="125" height="180" alt="K. R. Rao" /></td>
    <td width="25">&nbsp;</td>
    <td><img src="images/tutorial/hongrenwu.jpg" width="125" height="180" alt="Hong Ren Wu" /></td>
  </tr>
</table>
<p><strong>Abstract</strong></p>
<p align="justify">Traditional definition of digital picture coding covers compression of visual signals including still images and moving or motion pictures or image sequences or videos. Digital picture compression products, systems and applications proliferated over the past two decades, at a pace which had never been witnessed since the pioneering work by Goodall at Bell Labs in 1949, in visual communications, broadcasting and entertainment, including video telephony, video conferencing, digital television (TV) broadcasting including standard definition (SD), high definition (HD), and three-dimensional (3-D) video signals, IPTV (Internet protocol TV), IP CCTV (closed-circuits TV), video streaming and on-demand services, PACS (picture archiving and communication system) for biomedical imaging, satellite imaging, DVD (digital versatile disc) and HD DVD/Blu-ray products, broadband wireless and multimedia communications. Super-HD (SHD) and ultra-HD (UHD) TV are being standardized.
Human visual system (HVS) based picture coding research and development has been an important and very challenging topic in both theory and practice since the very beginning with an emphasis on constant picture quality coding based on rate-distortion (R-D) theory.  Its importance, relevance and urgency have become increasingly obvious to research and professional communities and industries to develop future generations of high quality picture coding standards, products and systems for quality user experience applications such as SHD or UHD video systems, digital cinema distribution systems, 3-D video/TV, immersive interactive visual systems, medical imaging and picture archiving systems for tele-medicine/health, and quality multimedia systems and services.  It aims at transforming visual communication services and entertainment from the "best efforts" to visual quality assured practice for relevant industries to be sustainable in the long run.
</p>

<p align="justify">This tutorial consists of three components, including an introduction to perceptual coding of digital pictures (PCP), HVS modelling for picture coders, and adaption of HVS models to picture coding. The introduction clarifies the theoretical foundation for perceptual picture coding against the backdrop of classical principles for picture coding.  It reviews the historical development of human perception-based approaches to picture coding, leading to the state-of-the-art.  It highlights various perceptual coding techniques at different periods and their incorporations in various picture coding standards. The tutorial in its second component provides a summary discussion on HVS characterisation and a comprehensive description of HVS threshold and supra-threshold models which have been successfully deployed in picture coding designs.  The adaptation of HVS models to PCP is developed focusing on three major categories at either perceptually lossless or perceptually lossy levels, including perceptual predictive coding, perceptual quantizer design and RpD (rate-perceptual-distortion) optimization. HVS-based pre- and post-filtering techniques are briefly discussed due to their unique roles in visual signal bandwidth reduction and minimisation of compression visual distortion which improves perceived picture quality. The tutorial concludes by highlighting a number of theoretical and practical challenges of this fascinating area in a field of engineering and technology which has been transforming our way of life.</p>

<p align="justify">The tutorial aims at providing the participants with a comprehensive treatment and knowledge of perceptual (i.e., HVS based) picture coding and compression, discussing formulations of perceptual picture coders which have been reported in recent years, facilitating rapid adoption and adaptation of various HVS models to picture coding products and systems for enhanced quality of experiences in digital media communication and entertainment services, and highlighting critical issues and challenges for the next generation high quality picture coding systems and applications.</p>

<br />
<p><a href="cft.php">Original Call for Tutorials</a></p>

<?php
echoEnd();
?>
